### EDA : Exploratory Data Analysis (탐색적 데이터 분석)

- EDA란? 
  - 데이터를 탐색하고 이해하기 위한 과정
  - 데이터셋의 구성, 변수 간의 관계, 이상치 및 결측치의 여부 등을 파악
  - 데이터의 특성을 시각화 및 요약하여 데이터의 패턴과 통계적 성질을 탐색

- 표준 정규분포 : 평균이 0이고 표준편차가 1인 정규분포

- 평균은 이상치에 영향을 많이 받음 / 중위값은 이상치에 덜 민감

- 절사 평균 : 데이터에서 일정 비율만큼 가장 큰 / 가장 작은 부분은 제거 후 평균

- IQR : Inter Quatile Range 사분위 범위 

  - 상위 25%와 하위 25% 사이의 범위 (Q3 - Q1)
  - 데이터의 이상치를 탐지하는 데 사용됨

- nobs : 갯수

  minmax : (최소값, 최대값)

  mean : 평균

  variance : 분산

  skewness : 왜도(좌측으로 치우쳐져 있는 경우 음수 값, 우측으로 치우쳐져 있는 경우 양수 값)

  kurtosis : 첨도(확률 분포나 데이터의 꼬리의 두께나 중앙 부분의 뾰족함을 측정)

- 범위(Range) 구하는 방법 : ptp (peak to peak)

- 도수분포표 : 데이터의 값들이 특정 구간 또는 범주에 속하는 빈도(도수)를 보여주는 표

- 결측치 : 데이터셋에서 값이 비어있거나 없는 경우

 

### Machine Learning 이란

- 문제를 풀기 위해서 컴퓨터 시스템에 데이터를 학습시켜서 모델을 만드는 것
- 지도학습 : 입력 데이터와 이에 해당하는 정답 데이터을 사용하여 모델을 학습
- 비지도학습 : 데이터가 주어지지 않은 상황에서 패턴이나 구조를 발견하고 모델을 학습하는 방법

- x : data,  독립변수, feature, 문제 
- y : target, 종속변수, label, 답
- 학습 : 입력받은 x와 y를 가지고 식을 만드는 것
- 옵티마이저(optimizer) : 가중치(w)와 편향(b)을 조정하여 손실 최소화 / 성능 지표 최대화하는 요소

- loss / cost function : 예측 값과 실제 값 사이의 오차를 계산하는 함수 (성능을 평가하고 최적화 하기 위해)
- 과대적합(overfitting) 
  - 주어진 입력 데이터에 비하여 모델의 복잡도가 너무 높아 
  - 입력 데이터의 잡음까지 fitting 하는 경향을 보이고, 일반화에 실패하는 상황 
  - 학습 데이터에만 과도하게 적합되어 실제 데이터에 대한 일반화 능력이 저하되는 현상
- 과소적합 (underfitting)
  - 주어진 입력 데이터에 비하여 모델의 복잡도가 너무 낮아 
  - 입력 데이터로부터 충분히 학습하지 못하는 상황



### ERROR

- 입력된 값 (문제(x값) / 정답(y값))
- 궁극적인 목표! x 값을 주면 y 값을 도출하게 만들고 싶다 (x와 y의 관계)

- 정답과 예측의 차이를 단순하게 더하면 판단을 제대로 내릴 수 없음

- 오차들을 제곱해서 더한 뒤 평균을 내는 방법 : Mean Squared Error (평균 제곱 오차)
- MSE는 값이 작을수록 모델의 예측이 실제값과 가깝다



### Gradient Descent 경사 하강법

- y = w * x + b
- 평균 제곱 오차(MSE) : 예측값과 실제값의 차이를 제곱한 후 평균
- 기울기가 점점 줄어들게 만들고 싶다 > MSE를 줄이겠다 > 정답에 가까워지고 싶다

- w랑 b를 정답에 가까워지게 하겠다



### Linear Regression (선형 회귀)

- 회귀분석이란? 
  - 종속 변수와 한 개 이상의 독립 변수간의 관계를 모델링하고 예측하기 위해 사용되는 분석 방법

- 선형 회귀 : 연속적인 데이터를 예측하고 싶을 때
- y : 출력 변수
- x : 입력 변수
- w : 가중치(회귀 계수)
- b : 절편
- 데이터 분할 : 학습에 필요한 데이터와 테스트에 필요한 데이터가 다르다
- test_size=0.3 : 전체 데이터 중에서 30%만 테스트용으로 선택 (나머지 70%는 학습용)

- random_state : 랜덤으로 가져오는 시드 고정
- 다항 회귀 (PolynomialFeatures)
  - 선형 회귀(Linear Regression)의 확장된 형태
  - 비선형 데이터를 모델링하는데 사용되는 회귀 기법
  - 독립 변수와 종속 변수 간의 비선형 관계를 다항식으로 모델링 함
  - 너무 낮은 차수는 데이터를 충분히 모델링하지 못하게 하고
  - 너무 높은 차수는 과적합(overfitting) 문제를 발생 시킴

